{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46845004-4791-49d5-b23f-f673d34b080b",
   "metadata": {},
   "source": [
    "## Aspect-Based Sentiment Analysis on Twitter Data\n",
    "\n",
    "<img align='right' src='https://git.sbg.ac.at/s1080384/sentimentanalysis/-/wikis/uploads/8729054731d3bf4f16e1d5a0b2fa23f5/absa.png' alt='An example of the four key sentiment elements of ABSA. (Zhang et al., 2022)' width='50%'>\n",
    "\n",
    "Recently, a more fine-grained \"aspect-based sentiment analysis\" (short ABSA) has been taking the lead from the traditional sentence and document-level sentiment classification. It's popularity has been fuelled by the increasing capabilities of deep learning models and the lacking granularity in convencional document-level sentiment analysis. ABSA **considers text data at the token level**, whereas document-level analyses are based on the assumption that the document is concerned with a single topic, which often proves untrue.\n",
    "\n",
    "Zhang et al. (2022) summarize this trend towards more fine-grained analysis levels:\n",
    "\n",
    "> _In the ABSA problem, the concerned target on which the sentiment is expressed shifts from an entire document to an entity or a certain aspect of an entity._\n",
    "\n",
    "The term \"aspect\" can generally refer to both the aspect of an entity as well as a special \"general\" aspect. Hence, it is often used to collectively refer to the entity or an entity's aspect.\n",
    "\n",
    "**ABSA encompasses** the identification of one or more of four sentiment elements. Depending on the goal researchers set, Zhang et al. (2022) divide their ABSA methods into either **Single ABSA** tasks (the more conventional method for ABSA, where a method is developed to tackle one single ABSA goal) or **Compound ABSA** tasks (more recent trends have moved towards developing methods that address two or more sentiment goals in a single method, thereby capturing the dependency between them).\n",
    "\n",
    "* **aspect category** _c_ defines a unique aspect of an entity and is supposed to fall into a category set C, predefined for each specific domain of interest. For example, `food` and `service` can be aspect categories for the restaurant domain.\n",
    "* **aspect term** _a_ is the opinion target which explicitly appears in the given text, e.g., `“pizza”` in the sentence “The pizza is delicious.” When the target is implicitly expressed (e.g., “It is overpriced!”), we denote the aspect term as a special one named “null”.\n",
    "* **opinion term** _o_ is the expression given by the opinion holder to express his/her sentiment towards the target. For instance, `“delicious”` is the opinion term in the running example “The pizza is delicious”.\n",
    "* **sentiment polarity** _p_ describes the orientation of the sentiment over an aspect category or an aspect term, which usually includes `positive`, `negative`, and `neutral`.\n",
    "\n",
    "<br>\n",
    "\n",
    "##### The Tasks of ABSA\n",
    "\n",
    "<img src=\"https://github.com/Christina1281995/demo-repo/blob/main/absatasks.png?raw=true\" width=\"50%\" align=\"right\">\n",
    "\n",
    "Based on the comprehensive and recent overview provided by Zhang et al. (2022), several methods were systematically identified for further investigation:\n",
    "Potential tasks of interest:\n",
    "\n",
    "- ATE (aspect term extraction)\n",
    "- ASC (aspect sentiment classification)\n",
    "- E2E (end 2 end, ATE + ASC)\n",
    "- ASTE (aspect sentiment triple extraction, ATE, OTE, ASC)\n",
    "\n",
    "Either a pipeline method consisting of an ATE and ASC methods, or one of the compound methods may suffice for ABSA on tweet data.\n",
    "All 4 above mentioned potential tasks were investigated concerning their documented performance on well-known datasets (mostly SemEval 2014, 2015, 2016 but also Mitchell et al.'s 2013 twitter dataset). The top scoring methods for each task are selected for more in-depth inspection. Priority was also given to methods that scored particularly well on the twitter dataset.\n",
    "\n",
    "\n",
    "<img src=\"https://git.sbg.ac.at/geo-social-analytics/geo-social-media/sentiment-analyses/uploads/a23ed12a3d3860816556bcf159a7adf2/methods_of_general_interest.png\" width=\"80%\">\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "\n",
    "##### Comparing published methodologies\n",
    "\n",
    "<details><summary>ATE Methods</summary>\n",
    "\n",
    "<img src=\"https://git.sbg.ac.at/geo-social-analytics/geo-social-media/sentiment-analyses/uploads/380415e631882f5cee2aba0c57eb4be3/image.png\">\n",
    "</details>\n",
    "\n",
    "<details><summary>ASC Methods</summary>\n",
    "\n",
    "<img src=\"https://git.sbg.ac.at/geo-social-analytics/geo-social-media/sentiment-analyses/uploads/91e300023dfe90e3c37a1a5dbc20b65b/image.png\">\n",
    "</details>\n",
    "\n",
    "<details><summary>End 2 End Methods</summary>\n",
    "\n",
    "<img src=\"https://git.sbg.ac.at/geo-social-analytics/geo-social-media/sentiment-analyses/uploads/5ab513146d2f580dc2dc5609c04e2950/image.png\">\n",
    "</details>\n",
    "\n",
    "<details><summary>ASTE Methods</summary>\n",
    "\n",
    "<img src=\"https://git.sbg.ac.at/geo-social-analytics/geo-social-media/sentiment-analyses/uploads/20a20dc8168d41741d32912887476858/image.png\">\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "<hr>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06fa112d-69f4-4a06-aacf-d1e5e98efb41",
   "metadata": {},
   "source": [
    "#### GRACE: Gradient Harmonized and Cascaded Labeling for Aspect-Based Sentiment Analysis\n",
    "\n",
    "The method designed by Luo et al. (2020), described in the paper [GRACE: Gradient Harmonized and Cascaded Labeling for Aspect-based Sentiment Analysis. Huaishao Luo, Lei Ji, Tianrui Li, Nan Duan, Daxin Jiang. Findings of EMNLP, 2020.](https://arxiv.org/abs/2009.10557), implements a gradient harmonized and cascaded labeling model. \n",
    "\n",
    "The method falls into the \"End 2 End\" category of aspect-based sentiment analysis tasks, meaning it solves two ABSA sub-tasks, ATE (asect term extraction) and ASC (aspect semtiment classification), in one model or methodology. Recent advances in the E2E methods leverage the interdependencies between aspect term detection and its sentiment classification to enhance model performances. This stands in contrast to pipeline approaches, which tackle one ABSA sub-task after the other in an isolated manner. \n",
    "\n",
    "<img src='https://github.com/ArrowLuo/GRACE/raw/master/accessory/Framework.png'>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "##### GRACE Model Architecture and Characteristics\n",
    "\n",
    "<img src=\"https://github.com/Christina1281995/demo-repo/blob/main/joint.PNG?raw=true\" align=\"right\" width=\"40%\">\n",
    "\n",
    "- Co-extraction of ATE and ASC\n",
    "- 2 cascading modules\n",
    "    - 12 stacked transformer encoder blocks for ATE\n",
    "    - 3 shared transformer encoder blocks and 2 transformer decoder blocks for ASC\n",
    "- Focus on interaction\n",
    "- Joint approach\n",
    "- Shared shallow layers (n=3)\n",
    "    - higher layers in BERT are usually task-specific \n",
    "    - it is assumed that can be useful to share the shallow layers \n",
    "    - generates a shared \"baseline understanding\"\n",
    "<img src=\"https://github.com/Christina1281995/demo-repo/blob/main/grad.PNG?raw=true\" align=\"right\" width=\"40%\">\n",
    "- **Virtual adversairal training**: the robustness of the model is improved bz preturbing the input data in small ways so that its difficult for the model to classify (to implement this, the direction and distance of the perturbations is calculated)\n",
    "- **Gradient harmonized loss**: the model is trained with cross entropy loss, but to optimise the model to \"focus\" more on the \"hard\" labels, a gradient norm is calculated for each label (where \"easy\" labels have low gradients) and a weight for the loss calculation is assigned to each label based on the gradient density (histogram statistic). The idea is to decrease the weight of loss form labels with low gradient norms.\n",
    "\n",
    "Architecture: \n",
    "\n",
    "- **Activation** function: GeLU (Gaussian Error Linear Unit, non-linear function that maps negative input values to negative outputs and positive input values to positive outputs)\n",
    "- Initial **tokenization and embeddings** (WordPiece, a subword tokenization method used for the original BERT model)\n",
    "    - A nn.Embeddings layer combines word embeddings, positional embeddings and token type embeddings (n=2)\n",
    "- n x the **encoder block** (12 in this configuration, same as original BERT model)\n",
    "    - Multi-head Scaled-dot product attention with Softmax to generate context layer\n",
    "    - 'Intermediate': linear layer and activation function\n",
    "    - 'Output': liner layer, layer normalisation, dropout\n",
    "- The **classification head** for ATE (nn.Linear, Softmax)\n",
    "- n x the **decoder block** (2 in this configuration)\n",
    "- The **classification head** for ASC (nn.Linear, Softmax)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d571b890",
   "metadata": {},
   "source": [
    "In this collapsed cell are a few key building blocks in coded implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8ff47dc",
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1578268696.py, line 96)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[69], line 96\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"BERT model for classification.\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# higher-level contents of one encoder\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertLayer, self).__init__()\n",
    "        self.attention = BertAttention(config)  # multi-head scaled-dot prodcut self-attention\n",
    "        self.intermediate = BertIntermediate(config)  # feed forward linear and normalisation\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):\n",
    "        attention_output = self.attention(hidden_states, attention_mask)\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "\n",
    "\n",
    "\n",
    "# An encoder block (x12 in GRACE)\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__()\n",
    "        layer = BertLayer(config)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)]) # 12 \n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
    "        all_encoder_layers = []\n",
    "        for layer_module in self.layer:\n",
    "            hidden_states = layer_module(hidden_states, attention_mask)\n",
    "            if output_all_encoded_layers:\n",
    "                all_encoder_layers.append(hidden_states)\n",
    "        if not output_all_encoded_layers:\n",
    "            all_encoder_layers.append(hidden_states)\n",
    "        return all_encoder_layers\n",
    "\n",
    "\n",
    "\n",
    " # pooler layer for summarization based on [CLS] token\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertPooler, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output\n",
    "\n",
    "\n",
    "\n",
    "# model class using pretrained configurations\n",
    "class BertModel(PreTrainedBertModel):\n",
    "    \"\"\"BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n",
    "    Params:\n",
    "        config: a BertConfig class instance with the configuration to build a new model\n",
    "    Inputs:\n",
    "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
    "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
    "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
    "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
    "            a `sentence B` token (see BERT paper for more details).\n",
    "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
    "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
    "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
    "            a batch has varying length sentences.\n",
    "        `output_all_encoded_layers`: boolean which controls the content of the `encoded_layers` output as described below. Default: `True`.\n",
    "    Outputs: Tuple of (encoded_layers, pooled_output)\n",
    "        `encoded_layers`: controled by `output_all_encoded_layers` argument:\n",
    "            - `output_all_encoded_layers=True`: outputs a list of the full sequences of encoded-hidden-states at the end\n",
    "                of each attention block (i.e. 12 full sequences for BERT-base, 24 for BERT-large), each\n",
    "                encoded-hidden-state is a torch.FloatTensor of size [batch_size, sequence_length, hidden_size],\n",
    "            - `output_all_encoded_layers=False`: outputs only the full sequence of hidden-states corresponding\n",
    "                to the last attention block of shape [batch_size, sequence_length, hidden_size],\n",
    "        `pooled_output`: a torch.FloatTensor of size [batch_size, hidden_size] which is the output of a\n",
    "            classifier pretrained on top of the hidden state associated to the first character of the\n",
    "            input (`CLF`) to train on the Next-Sentence task (see BERT's paper).\n",
    "    Example usage:\n",
    "    ```python\n",
    "    # Already been converted into WordPiece token ids\n",
    "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "    config = modeling.BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "    model = modeling.BertModel(config=config)\n",
    "    all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask)\n",
    "    ```\n",
    "\n",
    "\n",
    "\n",
    "# BertModel then again is used to compose a whole classification task workflow, e.g.:\n",
    "class BertForSequenceClassification(PreTrainedBertModel):\n",
    "    \"\"\"BERT model for classification.\n",
    "    This module is composed of the BERT model with a linear layer on top of\n",
    "    the pooled output.\n",
    "    Params:\n",
    "        `config`: a BertConfig class instance with the configuration to build a new model.\n",
    "        `num_labels`: the number of classes for the classifier. Default = 2.\n",
    "    Inputs:\n",
    "        `input_ids`: a torch.LongTensor of shape [batch_size, sequence_length]\n",
    "            with the word token indices in the vocabulary(see the tokens preprocessing logic in the scripts\n",
    "            `extract_features.py`, `run_classifier.py` and `run_squad.py`)\n",
    "        `token_type_ids`: an optional torch.LongTensor of shape [batch_size, sequence_length] with the token\n",
    "            types indices selected in [0, 1]. Type 0 corresponds to a `sentence A` and type 1 corresponds to\n",
    "            a `sentence B` token (see BERT paper for more details).\n",
    "        `attention_mask`: an optional torch.LongTensor of shape [batch_size, sequence_length] with indices\n",
    "            selected in [0, 1]. It's a mask to be used if the input sequence length is smaller than the max\n",
    "            input sequence length in the current batch. It's the mask that we typically use for attention when\n",
    "            a batch has varying length sentences.\n",
    "        `labels`: labels for the classification output: torch.LongTensor of shape [batch_size]\n",
    "            with indices selected in [0, ..., num_labels].\n",
    "    Outputs:\n",
    "        if `labels` is not `None`:\n",
    "            Outputs the CrossEntropy classification loss of the output with the labels.\n",
    "        if `labels` is `None`:\n",
    "            Outputs the classification logits of shape [batch_size, num_labels].\n",
    "    Example usage:\n",
    "    ```python\n",
    "    # Already been converted into WordPiece token ids\n",
    "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "    config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "        num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "    num_labels = 2\n",
    "    model = BertForSequenceClassification(config, num_labels)\n",
    "    logits = model(input_ids, token_type_ids, input_mask)\n",
    "\n",
    "\n",
    "# complete asc ate workflow initialisation:\n",
    "class BertForSequenceLabeling(PreTrainedBertModel):\n",
    "    #\n",
    "    def __init__(self, config, num_tp_labels, task_config):\n",
    "        super(BertForSequenceLabeling, self).__init__(config)\n",
    "        self.num_tp_labels = num_tp_labels\n",
    "        self.task_config = task_config\n",
    "\n",
    "        at_label_list = self.task_config[\"at_labels\"]\n",
    "        self.at_label_map = {i: label for i, label in enumerate(at_label_list)}\n",
    "        assert len(at_label_list) == 3, \"Hard code works when doing BIO strategy, \" \\\n",
    "                                        \"due to the middle step to generate span boundary.\"\n",
    "        self.I_AP_INDEX = 2     # Note: This operation works when doing BIO strategy\n",
    "        assert self.at_label_map[self.I_AP_INDEX] == \"I-AP\", \"A hard code need the index below.\"\n",
    "\n",
    "        self.num_encoder_labels = self.num_tp_labels[0]\n",
    "        self.bert = BertModel(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, self.num_encoder_labels)\n",
    "\n",
    "        if self.task_config[\"use_ghl\"]:\n",
    "            self.weighted_ce_loss_fct = WeightedCrossEntropy(ignore_index=-1)\n",
    "        else:\n",
    "            self.ce_loss_fct = CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "        ## Gradient balance <---\n",
    "        self.bins = 24\n",
    "        self.momentum = 0.75\n",
    "        self.edges = torch.arange(self.bins + 1).float() / self.bins\n",
    "        self.edges[-1] += 1e-6\n",
    "        self.acc_sum = torch.zeros(self.bins, dtype=torch.float)\n",
    "\n",
    "        self.decoder_bins = 24\n",
    "        self.decoder_momentum = 0.75\n",
    "        self.decoder_edges = torch.arange(self.bins + 1).float() / self.bins\n",
    "        self.decoder_edges[-1] += 1e-6\n",
    "        self.decoder_acc_sum = torch.zeros(self.bins, dtype=torch.float)\n",
    "        self.decoder_weight_gradient = None\n",
    "        self.decoder_weight_gradient_labels = None\n",
    "        ## --->\n",
    "\n",
    "        self.use_vat = self.task_config[\"use_vat\"]\n",
    "        if self.use_vat:\n",
    "            self.alpha = 1.\n",
    "            self.xi = 1e-6\n",
    "            self.epsilon = 2.\n",
    "            self.ip = 1\n",
    "\n",
    "        self.num_decoder_labels = self.num_tp_labels[1]\n",
    "        if config.hidden_size == 768:\n",
    "            decoder_config, _ = PreTrainedDecoderBertModel.get_config(\"decoder-bert-base\")\n",
    "        else:\n",
    "            raise ValueError(\"No implementation on such a decoder config.\")\n",
    "\n",
    "        self.decoder_shared_layer = self.task_config[\"decoder_shared_layer\"]\n",
    "        decoder_config.decoder_vocab_size = self.num_encoder_labels\n",
    "        decoder_config.num_decoder_layers = self.task_config[\"num_decoder_layer\"]\n",
    "        bert_position_embeddings_weight = self.bert.embeddings.position_embeddings.weight\n",
    "\n",
    "        # NOTE: DecoderBertModel is adapted from the Transformer decoder.\n",
    "        # It is not a decoder used as generation task. It is used as labeling task here.\n",
    "        self.decoder = DecoderBertModel(decoder_config, bert_position_embeddings_weight)\n",
    "        self.decoder_classifier = nn.Linear(config.hidden_size, self.num_decoder_labels)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = ACT2FN[config.hidden_act] # nn.Tanh()\n",
    "\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    # Virtual Adversarial Training Implementation\n",
    "    def vat_loss(self, input_ids, token_type_ids, attention_mask):\n",
    "        # LDS should be calculated before the forward for cross entropy\n",
    "        with torch.no_grad():\n",
    "            _pred_logits, _, _ = self.get_encoder_logits(input_ids, token_type_ids, attention_mask)\n",
    "            pred = F.softmax(_pred_logits, dim=2)\n",
    "\n",
    "        # prepare random unit tensor\n",
    "        batch_size_, seq_length_ = input_ids.size()\n",
    "        hidden_size_ = self.bert.config.hidden_size\n",
    "        d = torch.randn(batch_size_, seq_length_, hidden_size_, device=input_ids.device)\n",
    "\n",
    "        with _disable_tracking_bn_stats(self):\n",
    "            # calc adversarial direction\n",
    "            for _ in range(self.ip):\n",
    "                d.requires_grad_()\n",
    "                xi_d = self.xi * _l2_normalize_foremd(_mask_by_length(d, attention_mask))\n",
    "                xi_d.retain_grad()\n",
    "                words_embeddings_ = self.bert.embeddings.word_embeddings(input_ids)\n",
    "                pred_hat, _, _ = self.get_encoder_logits(words_embeddings_ + xi_d, token_type_ids, attention_mask,\n",
    "                                                   bool_input_embedding=True)\n",
    "                logp_hat_i = F.log_softmax(pred_hat, dim=2).view(-1, self.num_encoder_labels)\n",
    "                pred_i = pred.view(-1, self.num_encoder_labels)\n",
    "                adv_distance = F.kl_div(logp_hat_i, pred_i, reduction='batchmean')\n",
    "                adv_distance.backward()\n",
    "                d = xi_d.grad\n",
    "                self.zero_grad()\n",
    "\n",
    "            # calc LDS\n",
    "            r_adv = _l2_normalize_foremd(d.detach()) * self.epsilon\n",
    "            words_embeddings_ = self.bert.embeddings.word_embeddings(input_ids)\n",
    "\n",
    "            pred_hat, _, _ = self.get_encoder_logits(words_embeddings_+r_adv, token_type_ids, attention_mask,\n",
    "                                               bool_input_embedding=True)\n",
    "            logp_hat_i = F.log_softmax(pred_hat, dim=2).view(-1, self.num_encoder_labels)\n",
    "            pred_i = pred.view(-1, self.num_encoder_labels)\n",
    "            lds = F.kl_div(logp_hat_i, pred_i, reduction='batchmean')\n",
    "        return lds\n",
    "\n",
    "    # Gradient Harmonized Loss Implementation\n",
    "    def calculate_ce_gradient_weight(self, logits, labels, attention_mask, num_labels,\n",
    "                         acc_sum, bins, momentum, edges, weight_gradient=None, weight_gradient_labels=None):\n",
    "        device = logits.device\n",
    "        batch_size, sequence_length = labels.size()\n",
    "        # Here using crf_label_ids for CE labels have -1 value.\n",
    "        labels_onehot = torch.zeros(batch_size, sequence_length, num_labels, dtype=torch.float, device=device)\n",
    "        crf_label_ids = labels.clone()\n",
    "        crf_label_ids[crf_label_ids < 0] = 0.\n",
    "        labels_onehot.scatter_(2, crf_label_ids.unsqueeze(2), 1)\n",
    "        # gradient length\n",
    "        gradient = torch.abs(F.softmax(logits.detach(), dim=-1) - labels_onehot)\n",
    "\n",
    "        weights, acc_sum, weight_gradient, weight_gradient_labels \\\n",
    "            = self.statistic_weight(gradient, logits, labels, attention_mask, num_labels,\n",
    "                                    acc_sum, bins, momentum, edges, weight_gradient, weight_gradient_labels)\n",
    "\n",
    "        return weights, acc_sum, weight_gradient, weight_gradient_labels\n",
    "\n",
    "    def statistic_weight(self, gradient, logits, labels, attention_mask, num_labels,\n",
    "                         acc_sum, bins, momentum, edges,\n",
    "                         weight_gradient=None, weight_gradient_labels=None):\n",
    "        device = logits.device\n",
    "        batch_size, sequence_length = labels.size()\n",
    "\n",
    "        if weight_gradient is None:\n",
    "            weight_gradient = torch.zeros(self.bins).to(device)\n",
    "        if weight_gradient_labels is None:\n",
    "            weight_gradient_labels = torch.zeros(self.bins, num_labels).to(device)\n",
    "\n",
    "        edges = self.edges.to(device)\n",
    "        momentum = self.momentum\n",
    "        weights = torch.ones_like(logits)\n",
    "\n",
    "        valid_instance = attention_mask.unsqueeze(-1).expand(batch_size, sequence_length, num_labels)\n",
    "        valid_instance = valid_instance > 0\n",
    "        total_valid = max(valid_instance.float().sum().item(), 1.0)\n",
    "        n = 0  # n valid bins\n",
    "        for i in range(self.bins):\n",
    "            inds = (gradient >= edges[i]) & (gradient < edges[i + 1]) & valid_instance\n",
    "\n",
    "            num_in_bin_label = inds.sum(0).sum(0).to(dtype=weight_gradient_labels.dtype)\n",
    "            weight_gradient_labels[i, :] = weight_gradient_labels[i, :] + num_in_bin_label\n",
    "\n",
    "            num_in_bin = inds.sum().item()\n",
    "\n",
    "            weight_gradient[i] = weight_gradient[i] + num_in_bin\n",
    "\n",
    "            if num_in_bin > 0:\n",
    "                if momentum > 0:\n",
    "                    index_tensor = torch.tensor(i)\n",
    "                    val_ = torch.gather(acc_sum, dim=0, index=index_tensor)\n",
    "                    momentum_bins = momentum * float(val_.item()) + (1 - momentum) * num_in_bin\n",
    "                    weights[inds] = total_valid / momentum_bins\n",
    "                    acc_sum.scatter_(0, index_tensor, momentum_bins)\n",
    "                else:\n",
    "                    weights[inds] = total_valid / num_in_bin\n",
    "                n += 1\n",
    "\n",
    "        return weights, acc_sum, weight_gradient, weight_gradient_labels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bca3b79c",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/e3850199388f4983cc9799135977f0a6b06d5a79//images/chapter03_transformer-encoder-decoder.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8ba889a",
   "metadata": {},
   "source": [
    "In replicating the training described in the paper using a twitter training dataset (`twt1`), an F1 score of 0.7514 was achieved for aspect term extraction. However, for the aspect sentiment classification, an F1 score of only 0.5694 was achieved. \n",
    "\n",
    "Future work may investigate whether higher results may be achieved for the GRACE ASC sub-task to fully leverage an E2E model for twitter ABSA. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c212977-fb8b-44f2-bedd-35f9564b3b3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1f0d6d-1562-4437-a2b0-28e409038c86",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.append('../GRACE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594009c-99a9-403f-a3b7-1b6868e6610a",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/06/2023 08:15:39 - INFO - numexpr.utils -   Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "02/06/2023 08:15:39 - INFO - numexpr.utils -   NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from ate_asc_modeling_local_bert_file import BertForSequenceLabeling\n",
    "import ate_asc_modeling_local_bert_file\n",
    "from file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from ate_asc_features import ATEASCProcessor, convert_examples_to_features, get_labels\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from tokenization import BertTokenizer\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "import urllib.request\n",
    "import pandas as pd                                                    # data handling\n",
    "import xml.etree.cElementTree as ET                                    # XML file parsing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c231aa1-92bc-420d-8d21-9bb498de7c1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### GRACE Model Setup (Loading from last training Step and Epoch)\n",
    "\n",
    "log messages from last training step and epoch: <br>\n",
    "\n",
    "```\n",
    "\n",
    "Model saved to out_twt1_ateacs/pytorch_model.bin.9\n",
    "\n",
    "AT p:0.7365 \tr:0.7670\tf1:0.7514 \n",
    "\n",
    "AS p:0.5581 \tr:0.5811\tf1:0.5694 \n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad363e4-bfaa-4b78-9ac3-d241dec579ea",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# args set as per instructions by authors\n",
    "args = argparse.Namespace(\n",
    "\n",
    "    ## Required parameters\n",
    "    data_dir='../GRACE/data/', \n",
    "    bert_model='bert-base-uncased',\n",
    "    init_model=None,\n",
    "    task_name=\"ate_asc\",\n",
    "    data_name=\"twt1\",\n",
    "    train_file=None,\n",
    "    valid_file=None,\n",
    "    test_file=None,\n",
    "    output_dir='out_testing/', \n",
    "    \n",
    "    ## Other parameters\n",
    "    cache_dir=\"\",\n",
    "    max_seq_length=128,\n",
    "    do_train=False,\n",
    "    do_eval=False, \n",
    "    do_lower_case=True, \n",
    "    train_batch_size=32, \n",
    "    gradient_accumulation_steps=1,\n",
    "    eval_batch_size=32,\n",
    "    learning_rate=3e-06,\n",
    "    num_train_epochs=10, \n",
    "    warmup_proportion=0.1, \n",
    "    num_thread_reader=0, \n",
    "    no_cuda=False, \n",
    "    local_rank=-1, \n",
    "    seed=42, \n",
    "    fp16=False,\n",
    "    loss_scale=0,\n",
    "    verbose_logging=False, \n",
    "    server_ip='',\n",
    "    server_port='', \n",
    "    use_ghl=True, \n",
    "    use_vat=False, \n",
    "    use_decoder=True, \n",
    "    num_decoder_layer=2, \n",
    "    decoder_shared_layer=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a0ebde-2fab-4a48-a5d5-b76106e196ce",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)  # if you are using multi-GPU.\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9a68d4-c852-4688-b4b2-67fc1d7b7efa",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# manually setting device and gpu parameters\n",
    "device = 'cpu'\n",
    "n_gpu = 0\n",
    "data_name = args.data_name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd47db9-711b-424a-a209-8d1f15a26516",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "task_name = args.task_name.lower()\n",
    "\n",
    "task_config = {\n",
    "    \"use_ghl\": True,\n",
    "    \"use_vat\": False,\n",
    "    \"num_decoder_layer\": 2,\n",
    "    \"decoder_shared_layer\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fac104e-8214-45ac-8150-6467fc89cafc",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def dataloader_val(args, tokenizer, file_path, label_tp_list, set_type=\"val\"):\n",
    "\n",
    "    dataset = ATEASCProcessor(file_path=file_path, set_type=set_type)\n",
    "    print(\"Loaded val file: {}\".format(file_path))\n",
    "\n",
    "    eval_features = convert_examples_to_features(dataset.examples, label_tp_list,\n",
    "                                                 args.max_seq_length, tokenizer, verbose_logging=False)\n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_at_label_ids = torch.tensor([f.at_label_id for f in eval_features], dtype=torch.long)\n",
    "    all_as_label_ids = torch.tensor([f.as_label_id for f in eval_features], dtype=torch.long)\n",
    "\n",
    "    all_label_mask = torch.tensor([f.label_mask for f in eval_features], dtype=torch.long)\n",
    "    all_label_mask_X = torch.tensor([f.label_mask_X for f in eval_features], dtype=torch.long)\n",
    "\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_at_label_ids, all_as_label_ids,\n",
    "                              all_label_mask, all_label_mask_X)\n",
    "\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    return eval_dataloader, eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9660a39f-5914-4691-bd86-24b8c38676f0",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/06/2023 08:15:58 - INFO - tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\Christina\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "# load bert tokenizer (bert-base-uncased)\n",
    "tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=args.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a4fe93-d842-4e63-9824-9837b5a69886",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "DATASET_DICT={}\n",
    "DATASET_DICT[\"lap\"] = {\"train_file\":\"laptops_2014_train.txt\", \"valid_file\":\"laptops_2014_trial.txt\", \"test_file\":\"laptops_2014_test.gold.txt\"}\n",
    "DATASET_DICT[\"res\"] = {\"train_file\":\"restaurants_union_train.txt\", \"valid_file\":\"restaurants_union_trial.txt\", \"test_file\":\"restaurants_union_test.gold.txt\"}\n",
    "for i in [\"2014\", \"2015\", \"2016\"]:\n",
    "    DATASET_DICT[\"res{}\".format(i)] = {\"train_file\": \"restaurants_{}_train.txt\".format(i), \"valid_file\": \"restaurants_{}_trial.txt\".format(i), \"test_file\": \"restaurants_{}_test.gold.txt\".format(i)}\n",
    "for i in range(10):\n",
    "    DATASET_DICT[\"twt{}\".format(i+1)] = {\"train_file\":\"twitter_{}_train.txt\".format(i+1), \"valid_file\":\"twitter_{}_test.gold.txt\".format(i+1), \"test_file\":\"twitter_{}_test.gold.txt\".format(i+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3a6c89e-7521-4cbb-84f3-7c156ac86e8c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if data_name in DATASET_DICT:\n",
    "    args.train_file = DATASET_DICT[data_name][\"train_file\"]\n",
    "    args.valid_file = DATASET_DICT[data_name][\"valid_file\"]\n",
    "    args.test_file = DATASET_DICT[data_name][\"test_file\"]\n",
    "else:\n",
    "    assert args.train_file is not None\n",
    "    assert args.valid_file is not None\n",
    "    assert args.test_file is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bb514c0-1a48-45c6-b4cf-9852c4a6e94e",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../GRACE/data/twitter_1_train.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(args.data_dir, args.train_file)\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c1daa2-4e4a-4049-902a-32d590df4dad",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT Labels are: [O, B-AP, I-AP]\n",
      "AS Labels are: [O, NEGATIVE, POSITIVE, NEUTRAL]\n"
     ]
    }
   ],
   "source": [
    "# ATEASCProcessor reads data and splits it into corpus and label list for ATE and ASC\n",
    "dataset = ATEASCProcessor(file_path=file_path, set_type=\"train\")\n",
    "at_labels, as_labels = get_labels(dataset.label_tp_list)\n",
    "label_tp_list = (at_labels, as_labels)\n",
    "\n",
    "print(\"AT Labels are:\", \"[\"+\", \".join(label_tp_list[0])+\"]\")\n",
    "print(\"AS Labels are:\", \"[\"+\", \".join(label_tp_list[1])+\"]\")\n",
    "at_num_labels = len(label_tp_list[0])\n",
    "as_num_labels = len(label_tp_list[1])\n",
    "num_tp_labels = (at_num_labels, as_num_labels)\n",
    "\n",
    "task_config[\"at_labels\"] = label_tp_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7eb3d4d-edd4-4d73-8a0e-2d089bd60b81",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-AP', 2: 'I-AP'}\n",
      "{0: 'O', 1: 'NEGATIVE', 2: 'POSITIVE', 3: 'NEUTRAL'}\n"
     ]
    }
   ],
   "source": [
    "at_label_list, as_label_list = label_tp_list\n",
    "at_label_map = {i: label for i, label in enumerate(at_label_list)}\n",
    "as_label_map = {i: label for i, label in enumerate(as_label_list)}\n",
    "\n",
    "print(at_label_map)\n",
    "print(as_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0b23b4a-927a-4aa7-90a3-f62c32a76b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file, args, num_tp_labels, task_config, device):\n",
    "    model_file = model_file\n",
    "    if os.path.exists(model_file):\n",
    "        model_state_dict = torch.load(model_file, map_location='cpu')\n",
    "        print(\"Model loaded from %s\", model_file)\n",
    "        model = BertForSequenceLabeling.from_pretrained(args.bert_model, cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / 'distributed_{}'.format(args.local_rank),\n",
    "                                                        state_dict=model_state_dict, num_tp_labels=num_tp_labels,\n",
    "                                                        task_config=task_config)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model = None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a399c67a-bad1-4d5b-9c9b-d398bb3a8899",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from %s ../GRACE/out_twt1_ateacs/pytorch_model.bin.9\n",
      "loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\Christina\\.pytorch_pretrained_bert\\distributed_-1\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "extracting archive file C:\\Users\\Christina\\.pytorch_pretrained_bert\\distributed_-1\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\CHRIST~1\\AppData\\Local\\Temp\\tmpgptvruaa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/06/2023 08:19:08 - INFO - decoder_module -   loading archive file d:\\Users\\Christina\\Documents\\gitlab_vscode\\sentiment-analysis\\GRACE\\decoder-bert-base\n"
     ]
    }
   ],
   "source": [
    "# set model file to the last saved model after training epochs completed\n",
    "\n",
    "# CODE CHANGE NOTE: In this implementation (using a docker container for jupyter lab) the download of bert-base-uncased.tar.gz \n",
    "#into cache terminates before the whole file is successfully loaded. \n",
    "# Therefore an adapted ate_asc_modeling_local_bert_file.py is imported here which loads the model from a folder in the repo ('bert-base-uncased/bert-base-uncased.tar.gz')\n",
    "\n",
    "model_file = '../GRACE/out_twt1_ateacs/pytorch_model.bin.9'\n",
    "model = load_model(model_file, args, num_tp_labels, task_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9161e72-12e2-42f9-9022-f059b2e92eda",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if hasattr(model, 'module'):\n",
    "    print('has module')\n",
    "    model = model.module\n",
    "    \n",
    "# print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "daa9c473",
   "metadata": {
    "tags": []
   },
   "source": [
    "The model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5268432b-b9ec-4b5b-901f-916f3aed3235",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "hide-output",
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceLabeling(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (weighted_ce_loss_fct): WeightedCrossEntropy()\n",
       "  (decoder): DecoderBertModel(\n",
       "    (embeddings): BertDecoderEmbeddings(\n",
       "      (decoder_word_embeddings): Embedding(3, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): DecoderBertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): BertDecoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DecoderLayer(\n",
       "          (slf_attn): DecoderAttention(\n",
       "            (att): MultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DecoderBertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (enc_attn): DecoderAttention(\n",
       "            (att): MultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DecoderBertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DecoderBertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): DecoderLayer(\n",
       "          (slf_attn): DecoderAttention(\n",
       "            (att): MultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DecoderBertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (enc_attn): DecoderAttention(\n",
       "            (att): MultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DecoderBertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DecoderBertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model to eval mode (turn off training features e.g. dropout)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302d62b-65f8-4544-9f3a-26027f587c5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "### Testing Block (can be skipped)\n",
    "\n",
    "This code block serves to ensure the model loaded correctly.\n",
    "Uses just the last entry in twitter_1_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb109384-9175-4642-82c6-ecd932cfbac1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "DATALOADER_DICT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a81aa2-d45f-4129-a510-eb1b23deb78e",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "DATALOADER_DICT[\"ate_asc\"] = {\"eval\": dataloader_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdcce07-1b77-49dc-9caa-9d59ab3287b9",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "if task_name not in DATALOADER_DICT:\n",
    "    raise ValueError(\"Task not found: %s\" % (task_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f4500-a741-4c95-bd7e-8937afec2de6",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "eval_dataloader, eval_examples = DATALOADER_DICT[task_name][\"eval\"](args, tokenizer, file_path, label_tp_list=label_tp_list, set_type=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da11112-5481-4d69-bbe8-f5d67a36d928",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "for input_ids, input_mask, segment_ids, at_label_ids, as_label_ids, label_mask, label_mask_X in eval_dataloader:\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    at_label_ids = at_label_ids.to(device)\n",
    "    as_label_ids = as_label_ids.to(device)\n",
    "    label_mask = label_mask.to(device)\n",
    "    label_mask_X = label_mask_X.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49cb784-5cfb-4fae-baf9-98fe6c0fcd83",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # logits, decoder_logits = model(input_ids, segment_ids, input_mask)\n",
    "    logits, sequence_output, encoder_output = model.get_encoder_logits(input_ids, segment_ids, input_mask)\n",
    "    pred_dec_ids = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "    decoder_logits = model.get_decoder_logits(encoder_output, input_mask, label_mask_X, pred_dec_ids)\n",
    "    logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "    decoder_logits = torch.argmax(F.log_softmax(decoder_logits, dim=2), dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    decoder_logits = decoder_logits.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc656ce-120e-4f84-b503-a268ebf61352",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "at_label_ids = at_label_ids.to('cpu').numpy()\n",
    "as_label_ids = as_label_ids.to('cpu').numpy()\n",
    "label_mask = label_mask.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04779b54-0de6-4907-b1bd-76f6ab4e3c88",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "for i, mask_i in enumerate(label_mask):\n",
    "    temp_11 = []\n",
    "    temp_12 = []\n",
    "    temp_21 = []\n",
    "    temp_22 = []\n",
    "    for j, l in enumerate(mask_i):\n",
    "        if l > -1:\n",
    "            temp_11.append(at_label_map[at_label_ids[i][j]])\n",
    "            temp_12.append(at_label_map[logits[i][j]])\n",
    "            temp_21.append(as_label_map[as_label_ids[i][j]])\n",
    "            temp_22.append(as_label_map[decoder_logits[i][j]])\n",
    "\n",
    "print('Aspect Terms:')\n",
    "print(temp_11)\n",
    "print('Predicted Aspect Terms:')\n",
    "print(temp_12)\n",
    "print('\\nAspect Sentiment:')\n",
    "print(temp_21)\n",
    "print('Predicted Aspect Sentiment:')\n",
    "print(temp_22)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7acfe0ab-041c-4a5f-a718-d4ae2df7cc11",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Apply Model on Twemlab Goldstandard Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bd6bb3a-260e-44b9-b412-c36fa758f138",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "##### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5640ed8-8580-4dda-8caa-9081d092eff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets in goldstandard: 994\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>goldstandard</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000000000000001</td>\n",
       "      <td>beauty</td>\n",
       "      <td>who says summer is over; beautiful run in Edin...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000000000000002</td>\n",
       "      <td>none</td>\n",
       "      <td>Eid prayer in small heath park 7:30am sharp to...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200000000000000003</td>\n",
       "      <td>none</td>\n",
       "      <td>did the last one at Summerfield Park</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200000000000000004</td>\n",
       "      <td>none</td>\n",
       "      <td>that was Summerfield Park</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000000000000005</td>\n",
       "      <td>none</td>\n",
       "      <td>FREE led cycle ride from Edgbaston Reservoir, ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id   label  \\\n",
       "0  200000000000000001  beauty   \n",
       "1  200000000000000002    none   \n",
       "2  200000000000000003    none   \n",
       "3  200000000000000004    none   \n",
       "4  200000000000000005    none   \n",
       "\n",
       "                                                text goldstandard  \\\n",
       "0  who says summer is over; beautiful run in Edin...          yes   \n",
       "1  Eid prayer in small heath park 7:30am sharp to...          yes   \n",
       "2               did the last one at Summerfield Park          yes   \n",
       "3                          that was Summerfield Park          yes   \n",
       "4  FREE led cycle ride from Edgbaston Reservoir, ...          yes   \n",
       "\n",
       "   sentiment_label  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load TwEmLab Goldstandard\n",
    "tree1 = ET.parse('../Data/twemlab_goldstandards_original/birmingham_labels.xml')\n",
    "root1 = tree1.getroot()\n",
    "\n",
    "# create dataframe from xml file\n",
    "data1 = []\n",
    "for tweet in root1.findall('Tweet'):\n",
    "    id = tweet.find('ID').text\n",
    "    label = tweet.find('Label').text\n",
    "    data1.append((id, label))\n",
    "\n",
    "df1 = pd.DataFrame(data1,columns=['id','label'])\n",
    " # df1.head()\n",
    "    \n",
    "# Load TwEmLab Boston Tweets\n",
    "tree2 = ET.parse('../Data/twemlab_goldstandards_original/birmingham_tweets.xml')\n",
    "root2 = tree2.getroot()\n",
    "\n",
    "# create dataframe from xml file\n",
    "data2 = []\n",
    "for tweet in root2.findall('Tweet'):\n",
    "    id = tweet.find('ID').text\n",
    "    text = tweet.find('text').text\n",
    "    goldstandard = tweet.attrib.get(\"goldstandard\")\n",
    "    data2.append((id, text, goldstandard))\n",
    "\n",
    "df2 = pd.DataFrame(data2,columns=['id','text', 'goldstandard'])\n",
    "# df2.head()\n",
    "\n",
    " # merge the two separate dataframes based on id columns\n",
    "merge = pd.merge(df1, df2, on='id')\n",
    "\n",
    "# keep only the tweets that are part of the goldstandard\n",
    "twemlab = merge[merge['goldstandard'] == 'yes']\n",
    "print(f'Number of tweets in goldstandard: {len(twemlab)}')\n",
    "\n",
    "sentimemt_label_three = []\n",
    "# assign sentiment label (0, 1) based on emotion\n",
    "for index, row in twemlab.iterrows():\n",
    "    if row['label'] == 'beauty' or row['label'] == 'happiness':\n",
    "        sentimemt_label_three.append(1)\n",
    "    elif row['label'] == 'none':\n",
    "        sentimemt_label_three.append(0)\n",
    "    else: \n",
    "        sentimemt_label_three.append(-1)\n",
    "        \n",
    "twemlab['sentiment_label'] = sentimemt_label_three\n",
    "\n",
    "# check dataset\n",
    "twemlab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64809ec6-2493-4b6a-8cdd-63b4b40e905c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "#### Re-Format Text to match GRACE Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "289b6628-723f-478d-9501-42979dd77dba",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# text column to list\n",
    "text_list = list(twemlab['text'])\n",
    "\n",
    "# input format for GRACE model\n",
    "addition = ' - - O O O'\n",
    "convert_to_doc = []\n",
    "\n",
    "# iteratively apply re-formatting and save to new list\n",
    "for tweet in text_list:\n",
    "    words = tweet.split()\n",
    "    words_with_addition = []\n",
    "    for word in words:\n",
    "        new_word = word + addition\n",
    "        #print(new_word)\n",
    "        words_with_addition.append(new_word)\n",
    "    convert_to_doc.append(words_with_addition)\n",
    "\n",
    "# check outputs\n",
    "#print(convert_to_doc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6f6a2-251a-45b0-8df6-6bde2f243311",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "#### Save to .txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd6fcda6-6f31-40c5-997d-bfe1c2643fde",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"../Data/twemlab_goldstandards_original/original_reformatted_with_0s/twemlab_birmingham_formatted.txt\", mode = \"w\") as f:\n",
    "    for tweet in convert_to_doc:\n",
    "        for word in tweet:\n",
    "            f.write(\"%s\\n\" % word)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187a2ba-c597-4fbe-ad4b-26aeea5069e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "#### Run GRACE Model on new .txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aebb5e75-5c5f-4a05-b690-6e3672aaa5ff",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/twemlab_goldstandards_original/original_reformatted_with_0s/twemlab_birmingham_formatted.txt\n"
     ]
    }
   ],
   "source": [
    "#file_path = os.path.join(args.data_dir, args.train_file)\n",
    "file_path = \"../Data/twemlab_goldstandards_original/original_reformatted_with_0s/twemlab_birmingham_formatted.txt\"\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e3bd5f5-419d-424d-a502-0a91f935f2ab",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "DATALOADER_DICT = {}\n",
    "# only \"eval\" state is needed (\"train\" is left out)\n",
    "DATALOADER_DICT[\"ate_asc\"] = {\"eval\":dataloader_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27707ca4-b9eb-4319-a159-503b9b2643c7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded val file: ../Data/twemlab_goldstandards_original/original_reformatted_with_0s/twemlab_birmingham_formatted.txt\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader, eval_examples = DATALOADER_DICT[task_name][\"eval\"](args, tokenizer, file_path, label_tp_list=label_tp_list, set_type=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e66df80a-90a3-4ed7-88ec-79b397ec04b3",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# empty lists for outputs\n",
    "pred_aspect_terms = []\n",
    "pred_aspect_sentiments = []\n",
    "\n",
    "# eval_dataloader contains the pre-processed, tokenized inputs (input has been reformatted for GRACE beforehand)\n",
    "for input_ids, input_mask, segment_ids, at_label_ids, as_label_ids, label_mask, label_mask_X in eval_dataloader:\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    at_label_ids = at_label_ids.to(device)\n",
    "    as_label_ids = as_label_ids.to(device)\n",
    "    label_mask = label_mask.to(device)\n",
    "    label_mask_X = label_mask_X.to(device)\n",
    "    \n",
    "    # get predictions with argmax log-softmax probabilities\n",
    "    # predicted aspect term ids from logits (encoder)\n",
    "    # predicted asepct sentiment ids from decoder logits\n",
    "    with torch.no_grad():\n",
    "        # logits, decoder_logits = model(input_ids, segment_ids, input_mask)\n",
    "        logits, sequence_output, encoder_output = model.get_encoder_logits(input_ids, segment_ids, input_mask)\n",
    "        pred_dec_ids = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "        decoder_logits = model.get_decoder_logits(encoder_output, input_mask, label_mask_X, pred_dec_ids)\n",
    "        logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "        decoder_logits = torch.argmax(F.log_softmax(decoder_logits, dim=2), dim=2)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        decoder_logits = decoder_logits.detach().cpu().numpy()\n",
    "        \n",
    "    at_label_ids = at_label_ids.to('cpu').numpy()\n",
    "    as_label_ids = as_label_ids.to('cpu').numpy()\n",
    "    label_mask = label_mask.to('cpu').numpy()\n",
    "    \n",
    "    for i, mask_i in enumerate(label_mask):\n",
    "        #temp_11 = []\n",
    "        temp_12 = []\n",
    "        #temp_21 = []\n",
    "        temp_22 = []\n",
    "        for j, l in enumerate(mask_i):\n",
    "            if l > -1:\n",
    "                # no at_label_ids or as_label_ids because there is no ground truth data in this dataset\n",
    "                #temp_11.append(at_label_map[at_label_ids[i][j]])\n",
    "                temp_12.append(at_label_map[logits[i][j]])\n",
    "                #temp_21.append(as_label_map[as_label_ids[i][j]])\n",
    "                temp_22.append(as_label_map[decoder_logits[i][j]])\n",
    "                \n",
    "        pred_aspect_terms.append(temp_12)\n",
    "        pred_aspect_sentiments.append(temp_22)\n",
    "\n",
    "# add new aspect term labels and aspect sentiment labels as columns to twemlab dataframe\n",
    "twemlab['aspect_term_preds'] = pred_aspect_terms\n",
    "twemlab['aspect_senti_preds'] = pred_aspect_sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e29aec6f-98d8-4a0a-a236-d6c1b555f5f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Extract Aspect Terms and Sentiment Aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cb091bb-29cd-4486-9261-d206b7b1c091",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# extract aspect term and sentiment and store in twemlab dataframe\n",
    "aspect_terms = []\n",
    "aspect_sentiments = []\n",
    "\n",
    "# for every row (tweet)\n",
    "for idx, row in twemlab.iterrows():\n",
    "    \n",
    "    row_aspect_terms = []\n",
    "    row_aspect_sentiments = [] \n",
    "\n",
    "    # get text length\n",
    "    words = row['text'].split()\n",
    "    count_words = len(words)\n",
    "    \n",
    "    # get token length (may differ from text length)\n",
    "    tokens = row['aspect_senti_preds']\n",
    "    token_counts = len(tokens)\n",
    "    \n",
    "    # for every word in tweet --> check if it's an aspect term and save\n",
    "    for i in range(count_words):\n",
    "        if row['aspect_term_preds'][i] == 'B-AP':\n",
    "            term = words[i]\n",
    "                   \n",
    "            # for remaining words\n",
    "            for j in range(i, count_words):\n",
    "                if row['aspect_term_preds'][j] == 'I-AP':\n",
    "                    term = term + ' ' + words[j]\n",
    "            \n",
    "            row_aspect_terms.append(term)\n",
    "    \n",
    "    aspect_terms.append(row_aspect_terms)\n",
    "    \n",
    "    # for every token --> extract sentiment\n",
    "    for i in range(token_counts):\n",
    "        if row['aspect_term_preds'][i] == 'B-AP':\n",
    "            sent = tokens[i]\n",
    "            \n",
    "            # for remaining tokens\n",
    "            for j in range(i, token_counts):\n",
    "                if row['aspect_term_preds'][j] == 'I-AP':\n",
    "                    sent = sent + ' ' + tokens[j]\n",
    "            \n",
    "            row_aspect_sentiments.append(sent)\n",
    "    \n",
    "    aspect_sentiments.append(row_aspect_sentiments)\n",
    "            \n",
    "twemlab['aspect_terms'] = aspect_terms\n",
    "twemlab['aspect_sentiments'] = aspect_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec5ed757-43c4-47a4-99f6-87a1a3db89eb",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e4f33 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e4f33_row0_col0, #T_e4f33_row0_col1, #T_e4f33_row0_col2, #T_e4f33_row0_col3, #T_e4f33_row0_col4, #T_e4f33_row1_col0, #T_e4f33_row1_col1, #T_e4f33_row1_col2, #T_e4f33_row1_col3, #T_e4f33_row1_col4, #T_e4f33_row2_col0, #T_e4f33_row2_col1, #T_e4f33_row2_col2, #T_e4f33_row2_col3, #T_e4f33_row2_col4, #T_e4f33_row3_col0, #T_e4f33_row3_col1, #T_e4f33_row3_col2, #T_e4f33_row3_col3, #T_e4f33_row3_col4, #T_e4f33_row4_col0, #T_e4f33_row4_col1, #T_e4f33_row4_col2, #T_e4f33_row4_col3, #T_e4f33_row4_col4 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e4f33\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e4f33_level0_col0\" class=\"col_heading level0 col0\" >Text</th>\n",
       "      <th id=\"T_e4f33_level0_col1\" class=\"col_heading level0 col1\" >Label</th>\n",
       "      <th id=\"T_e4f33_level0_col2\" class=\"col_heading level0 col2\" >sentiment_label</th>\n",
       "      <th id=\"T_e4f33_level0_col3\" class=\"col_heading level0 col3\" >Aspect Terms</th>\n",
       "      <th id=\"T_e4f33_level0_col4\" class=\"col_heading level0 col4\" >Aspect Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e4f33_level0_row0\" class=\"row_heading level0 row0\" >904</th>\n",
       "      <td id=\"T_e4f33_row0_col0\" class=\"data row0 col0\" >Christmas Fayre Sat 12 Dec 1.30 to 4.30 Hole Farm Trekking Centre Woodgate Valley Country Park Grotto Pony Rides Stalls Raffle Refreshments</td>\n",
       "      <td id=\"T_e4f33_row0_col1\" class=\"data row0 col1\" >none</td>\n",
       "      <td id=\"T_e4f33_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_e4f33_row0_col3\" class=\"data row0 col3\" >['Woodgate Valley Country Park']</td>\n",
       "      <td id=\"T_e4f33_row0_col4\" class=\"data row0 col4\" >['NEUTRAL NEUTRAL NEUTRAL NEUTRAL']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4f33_level0_row1\" class=\"row_heading level0 row1\" >644</th>\n",
       "      <td id=\"T_e4f33_row1_col0\" class=\"data row1 col0\" >Sunshine love in moseley park yesterday. #babysmiles </td>\n",
       "      <td id=\"T_e4f33_row1_col1\" class=\"data row1 col1\" >happiness</td>\n",
       "      <td id=\"T_e4f33_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "      <td id=\"T_e4f33_row1_col3\" class=\"data row1 col3\" >['moseley']</td>\n",
       "      <td id=\"T_e4f33_row1_col4\" class=\"data row1 col4\" >['POSITIVE']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4f33_level0_row2\" class=\"row_heading level0 row2\" >841</th>\n",
       "      <td id=\"T_e4f33_row2_col0\" class=\"data row2 col0\" >Running on treadmill is soul destroying, give me Sutton Park in sun, wind, rain or snow any day\r\n",
       " \r\n",
       "#NoBrainer</td>\n",
       "      <td id=\"T_e4f33_row2_col1\" class=\"data row2 col1\" >happiness</td>\n",
       "      <td id=\"T_e4f33_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "      <td id=\"T_e4f33_row2_col3\" class=\"data row2 col3\" >[]</td>\n",
       "      <td id=\"T_e4f33_row2_col4\" class=\"data row2 col4\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4f33_level0_row3\" class=\"row_heading level0 row3\" >132</th>\n",
       "      <td id=\"T_e4f33_row3_col0\" class=\"data row3 col0\" >Game postponed due to waterlogged pitch in Cardiff :( Boys putting a shift in at selly park as countdown to the uni game starts</td>\n",
       "      <td id=\"T_e4f33_row3_col1\" class=\"data row3 col1\" >sadness</td>\n",
       "      <td id=\"T_e4f33_row3_col2\" class=\"data row3 col2\" >-1</td>\n",
       "      <td id=\"T_e4f33_row3_col3\" class=\"data row3 col3\" >['uni']</td>\n",
       "      <td id=\"T_e4f33_row3_col4\" class=\"data row3 col4\" >['NEUTRAL']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4f33_level0_row4\" class=\"row_heading level0 row4\" >769</th>\n",
       "      <td id=\"T_e4f33_row4_col0\" class=\"data row4 col0\" >...heading down to Moseley Bog for the official unofficial festival inabit. coming?   </td>\n",
       "      <td id=\"T_e4f33_row4_col1\" class=\"data row4 col1\" >none</td>\n",
       "      <td id=\"T_e4f33_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_e4f33_row4_col3\" class=\"data row4 col3\" >['Moseley Bog']</td>\n",
       "      <td id=\"T_e4f33_row4_col4\" class=\"data row4 col4\" >['NEUTRAL NEUTRAL']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e6bb35e9d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_cols = twemlab[['text','label', 'sentiment_label','aspect_terms', 'aspect_sentiments']]\n",
    "col_names = {'text': 'Text', 'label': 'Label', 'sentimemt_label': 'Sentiment', 'aspect_terms': 'Aspect Terms', 'aspect_sentiments': 'Aspect Sentiments'}\n",
    "demo_cols = demo_cols.rename(columns=col_names)\n",
    "demo_cols.sample(5).style.set_properties(**{'text-align': 'left'}).set_table_styles([dict(selector = 'th', props=[('text-align', 'left')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39f9a71e-40a0-4d1a-9339-f214a859f618",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Example of how the GRACE results look\n",
      "\n",
      "Text:\tNext Sat  Our Big Gig Festival in Summerfield Park  \n",
      "\n",
      "Asp.Terms:\t['O', 'O', 'O', 'O', 'B-AP', 'O', 'O', 'O', 'O']\n",
      "Asp.Sents:\t['POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE']\n",
      "\n",
      "ATE:\t['Gig']\n",
      "ASC:\t['POSITIVE']\n",
      "\n",
      "Goldstandard: 0\n"
     ]
    }
   ],
   "source": [
    "index = 786\n",
    "\n",
    "print(f\"An Example of how the GRACE results look\\n\\nText:\\t{twemlab.iloc[index]['text']}\\n\\nAsp.Terms:\\t{twemlab.iloc[index]['aspect_term_preds']}\\nAsp.Sents:\\t{twemlab.iloc[index]['aspect_senti_preds']}\\n\\nATE:\\t{twemlab.iloc[index]['aspect_terms']}\\nASC:\\t{twemlab.iloc[index]['aspect_sentiments']}\\n\\nGoldstandard: {twemlab.iloc[index]['sentiment_label']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91429ba4-92c9-423c-8672-92aa4b8f6faf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "To get an indication of how well the model is classifying the aspect terms and their sentiments, a make-shift comparison to the goldstandard labels can me made. Note that the goldstandard annotations differ from the GRACE model output:\n",
    "- The goldstandard was labelled with emotions, whereas GRACE now identifies sentments (pos, neu, neg)\n",
    "- The goldstandard was labelled per document, i.e. the entire tweet, whereas GRACE breaks down the document into the token level and can identify several aspects within one tweet, each potentially with differnt sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c56107a-aacb-49d2-ada0-310c3cb6ae17",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the aspect sentiment classifcation with the overall sentiment in the twemlab goldstandard:\n",
      "\n",
      "Matches:      613  (61.7%)\n",
      "No Matches:   194  (19.5%)\n",
      "Not Uniform:   18   (1.8%)\n",
      "N/A:          169  (17.0%)\n"
     ]
    }
   ],
   "source": [
    "# compare the aspect sentiments with the twemlab sentiments\n",
    "\n",
    "match = 0          # sentiment tokens uniformly match goldstandard sentiment (incl. no-list on sentiment type \"none\")\n",
    "nomatch = 0        # sentiment tokens are uniformly different to goldstandard sentiment\n",
    "not_uniform = 0    # sentiment tokens are not uniform\n",
    "n_a = 0            # empty sentiment tokens list (that does not match with sentiment label 'none')\n",
    "counter = 0        # overall rows\n",
    "\n",
    "for idx, row in twemlab.iterrows():\n",
    "    counter += 1\n",
    "    \n",
    "    # if there is more than 1 list of aspect sentiment tokens\n",
    "    if len(row['aspect_sentiments']) > 1:\n",
    "        \n",
    "        # join them together into one list\n",
    "        all_tokens = ' '.join(row['aspect_sentiments'])\n",
    "        all_tokens = all_tokens.split()\n",
    "        first_token = all_tokens[0]\n",
    "        \n",
    "        # check if tokens are the same, e.g. ['NEUTRAL NEUTRAL', 'NEUTRAL NEUTRAL']\n",
    "        if all(token == first_token for token in all_tokens):\n",
    "            if first_token == 'POSITIVE' and row['sentiment_label'] == 1: match += 1\n",
    "            elif first_token == 'NEUTRAL' and row['sentiment_label'] == 0: match += 1\n",
    "            elif first_token == 'NEGATIVE' and row['sentiment_label'] == -1: match += 1\n",
    "            else: nomatch += 1 \n",
    "        else: not_uniform += 1\n",
    "\n",
    "    # if there is just 1 list of aspect sentiment tokens\n",
    "    elif len(row['aspect_sentiments']) == 1:\n",
    "        \n",
    "        tokens = row['aspect_sentiments'][0].split()\n",
    "        first_token = tokens[0]\n",
    "        \n",
    "        # if the list has more than one token\n",
    "        if len(tokens) > 1:\n",
    "            # check if tokens are the same  e.g. ['POSITIVE POSITIVE POSITIVE']\n",
    "            if all(token == first_token for token in tokens):\n",
    "                #print(f\"row asp sents: {row['aspect_sentiments']}\")\n",
    "                if first_token == 'POSITIVE' and row['sentiment_label'] == 1: match += 1\n",
    "                elif first_token == 'NEUTRAL' and row['sentiment_label'] == 0: match += 1\n",
    "                elif first_token == 'NEGATIVE' and row['sentiment_label'] == -1: match += 1\n",
    "                else: nomatch += 1\n",
    "            else: not_uniform += 1\n",
    "        \n",
    "        # if the list has only one entry\n",
    "        elif len(tokens) == 1:\n",
    "            if row['aspect_sentiments'][0] == 'POSITIVE' and row['sentiment_label'] == 1: match += 1\n",
    "            elif row['aspect_sentiments'][0] == 'NEUTRAL' and row['sentiment_label'] == 0: match += 1\n",
    "            elif row['aspect_sentiments'][0] == 'NEGATIVE' and row['sentiment_label'] == -1: match += 1\n",
    "            else: nomatch += 1\n",
    "        \n",
    "        else:\n",
    "            print(\"issue\")\n",
    "    \n",
    "    # empty list\n",
    "    else:\n",
    "        if row['sentiment_label'] == 0: match += 1\n",
    "        else: n_a += 1\n",
    "\n",
    "print(\"Comparing the aspect sentiment classifcation with the overall sentiment in the twemlab goldstandard:\\n\")\n",
    "print(f\"Matches:      {match}  ({np.round((match/counter)*100, 1)}%)\\nNo Matches:   {nomatch}  ({np.round((nomatch/counter)*100, 1)}%)\\nNot Uniform:   {not_uniform}   ({np.round((not_uniform/counter)*100, 1)}%)\\nN/A:          {n_a}  ({np.round((n_a/counter)*100, 1)}%)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adaaba27-6833-45a1-afa6-2235a9876b6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Apply Model on AIFER Twitter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc5bf8b-10d2-4944-a002-c3d5a799486e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a678b80-e121-489a-b59e-fec0bfe7bfc6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10749</th>\n",
       "      <td>2021-07-31 17:04:21</td>\n",
       "      <td>@MDegen55 @debbslovesnate I wish you a Good ni...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7070</th>\n",
       "      <td>2021-07-21 17:19:01</td>\n",
       "      <td>@MDegen55 All Stana Katic Fans of the World. H...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8624</th>\n",
       "      <td>2021-07-25 08:56:22</td>\n",
       "      <td>@MrsUnloveable Falle... 😁😁😁</td>\n",
       "      <td>POINT (7.589509999999999 50.34630250000001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>2021-07-05 16:09:07</td>\n",
       "      <td>@MDegen55 Good night &amp; nice Tuesday @LawrenCal...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>2021-07-18 07:54:22</td>\n",
       "      <td>@BuddyCoco64 @Jenny_S3005 @ASaramantinou @inax...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>2021-07-06 11:02:33</td>\n",
       "      <td>@nlopes952 @pocs80 @AnetteRuff1 @piaroos1 @moa...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>2021-07-16 07:00:53</td>\n",
       "      <td>@MDegen55 Hello AnnaBionda. Have a magical Fri...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>2021-07-18 07:48:39</td>\n",
       "      <td>@pocs80 @Jenny_S3005 @MDegen55 Good morning Ju...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>2021-07-16 07:16:28</td>\n",
       "      <td>@MDegen55 GOOD MORNING GIANNIS. HAVE A BEAUTIF...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>2021-07-13 21:23:12</td>\n",
       "      <td>@MDegen55 @KatanaHugo Good evening and good Ni...</td>\n",
       "      <td>POINT (7.265915499999999 50.45803549999999)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                               text  \\\n",
       "10749  2021-07-31 17:04:21  @MDegen55 @debbslovesnate I wish you a Good ni...   \n",
       "7070   2021-07-21 17:19:01  @MDegen55 All Stana Katic Fans of the World. H...   \n",
       "8624   2021-07-25 08:56:22                        @MrsUnloveable Falle... 😁😁😁   \n",
       "1269   2021-07-05 16:09:07  @MDegen55 Good night & nice Tuesday @LawrenCal...   \n",
       "5313   2021-07-18 07:54:22  @BuddyCoco64 @Jenny_S3005 @ASaramantinou @inax...   \n",
       "1515   2021-07-06 11:02:33  @nlopes952 @pocs80 @AnetteRuff1 @piaroos1 @moa...   \n",
       "4483   2021-07-16 07:00:53  @MDegen55 Hello AnnaBionda. Have a magical Fri...   \n",
       "5306   2021-07-18 07:48:39  @pocs80 @Jenny_S3005 @MDegen55 Good morning Ju...   \n",
       "4494   2021-07-16 07:16:28  @MDegen55 GOOD MORNING GIANNIS. HAVE A BEAUTIF...   \n",
       "3865   2021-07-13 21:23:12  @MDegen55 @KatanaHugo Good evening and good Ni...   \n",
       "\n",
       "                                              geom  \n",
       "10749  POINT (7.265915499999999 50.45803549999999)  \n",
       "7070   POINT (7.265915499999999 50.45803549999999)  \n",
       "8624   POINT (7.589509999999999 50.34630250000001)  \n",
       "1269   POINT (7.265915499999999 50.45803549999999)  \n",
       "5313   POINT (7.265915499999999 50.45803549999999)  \n",
       "1515   POINT (7.265915499999999 50.45803549999999)  \n",
       "4483   POINT (7.265915499999999 50.45803549999999)  \n",
       "5306   POINT (7.265915499999999 50.45803549999999)  \n",
       "4494   POINT (7.265915499999999 50.45803549999999)  \n",
       "3865   POINT (7.265915499999999 50.45803549999999)  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COVID dataset\n",
    "dataset = pd.read_csv(\"../Data/Disaster_responses/ahrtal_tweets.csv\", sep=\"\\t\")\n",
    "\n",
    "# MONKEYPOX dataset\n",
    "# dataset = pd.read_csv(\"https://git.sbg.ac.at/s1080384/sentimentanalysis/-/raw/main/data/100k_monkeypox.csv\")\n",
    "\n",
    "# filter for English tweets\n",
    "lang = ['en']\n",
    "en_dataset = dataset[dataset['tweet_lang'].isin(lang)]\n",
    "\n",
    "# exclude columns that aren't needed (for now)\n",
    "data = en_dataset[['date', 'text', 'geom']]\n",
    "\n",
    "# date handling (for animated map)\n",
    "#data['year'] = [pd.to_datetime(x).year for x in data['date']]\n",
    "#data['month'] = [pd.to_datetime(x).to_period('M') for x in data['date']]\n",
    "#data['week'] = [pd.to_datetime(x).to_period('W') for x in data['date']]\n",
    "#data['day'] = [pd.to_datetime(x).to_period('D') for x in data['date']]\n",
    "# data['month'] = data.apply(lambda row: pd.to_datetime(row[\"date\"]).to_period('M'), axis=1)\n",
    "\n",
    "# get subset to speed up demos and testing\n",
    "data_subset = data.sample(1000)\n",
    "data_subset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e2621-839e-4fad-912e-76b57a9d7197",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "#### Re-format Text to match GRACE Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3289bec4-a3fc-4776-84b5-bb163b50ba25",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# text column to list\n",
    "text_list = list(data_subset['text'])\n",
    "\n",
    "# input format for GRACE model\n",
    "addition = ' - - O O O'\n",
    "convert_to_doc = []\n",
    "\n",
    "# iteratively apply re-formatting and save to new list\n",
    "for tweet in text_list:\n",
    "    words = tweet.split()\n",
    "    words_with_addition = []\n",
    "    for word in words:\n",
    "        new_word = word + addition\n",
    "        #print(new_word)\n",
    "        words_with_addition.append(new_word)\n",
    "    convert_to_doc.append(words_with_addition)\n",
    "\n",
    "# check outputs\n",
    "#print(convert_to_doc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af52b5-b4a8-4d5f-bd67-1ee4bbadbf81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "#### Save to .txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a736de39-873d-41f0-a0f1-7e8fca9217cd",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"../Data/Disaster_responses/aifer_reformatted.txt\", mode = \"w\") as f:\n",
    "    for tweet in convert_to_doc:\n",
    "        for word in tweet:\n",
    "            f.write(\"%s\\n\" % word)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62073686-8bee-4fb6-aa59-b60763f209a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "#### Run GRACE Model on new .txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a72fae9-8c8c-45fc-b7b3-91bd4ad80367",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Disaster_responses/aifer_reformatted.txt\n"
     ]
    }
   ],
   "source": [
    "#file_path = os.path.join(args.data_dir, args.train_file)\n",
    "file_path = '../Data/Disaster_responses/aifer_reformatted.txt'\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3036d6a5-e55a-4e1a-81d6-3a46dca96f77",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "DATALOADER_DICT = {}\n",
    "# only \"eval\" state is needed (\"train\" is left out)\n",
    "DATALOADER_DICT[\"ate_asc\"] = {\"eval\":dataloader_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "540404c3-db9c-4213-8a21-9450be5047f4",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded val file: ../Data/Disaster_responses/aifer_reformatted.txt\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader, eval_examples = DATALOADER_DICT[task_name][\"eval\"](args, tokenizer, file_path, label_tp_list=label_tp_list, set_type=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bcdd3e4-8c5e-4014-844f-777c5f7c7bd1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "pred_aspect_terms = []\n",
    "pred_aspect_sentiments = []\n",
    "\n",
    "for input_ids, input_mask, segment_ids, at_label_ids, as_label_ids, label_mask, label_mask_X in eval_dataloader:\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    at_label_ids = at_label_ids.to(device)\n",
    "    as_label_ids = as_label_ids.to(device)\n",
    "    label_mask = label_mask.to(device)\n",
    "    label_mask_X = label_mask_X.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # logits, decoder_logits = model(input_ids, segment_ids, input_mask)\n",
    "        logits, sequence_output, encoder_output = model.get_encoder_logits(input_ids, segment_ids, input_mask)\n",
    "        pred_dec_ids = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "        decoder_logits = model.get_decoder_logits(encoder_output, input_mask, label_mask_X, pred_dec_ids)\n",
    "        logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "        decoder_logits = torch.argmax(F.log_softmax(decoder_logits, dim=2), dim=2)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        decoder_logits = decoder_logits.detach().cpu().numpy()\n",
    "        \n",
    "    at_label_ids = at_label_ids.to('cpu').numpy()\n",
    "    as_label_ids = as_label_ids.to('cpu').numpy()\n",
    "    label_mask = label_mask.to('cpu').numpy()\n",
    "    \n",
    "    for i, mask_i in enumerate(label_mask):\n",
    "        #temp_11 = []\n",
    "        temp_12 = []\n",
    "        #temp_21 = []\n",
    "        temp_22 = []\n",
    "        for j, l in enumerate(mask_i):\n",
    "            if l > -1:\n",
    "                #temp_11.append(at_label_map[at_label_ids[i][j]])\n",
    "                temp_12.append(at_label_map[logits[i][j]])\n",
    "                #temp_21.append(as_label_map[as_label_ids[i][j]])\n",
    "                temp_22.append(as_label_map[decoder_logits[i][j]])\n",
    "                \n",
    "        pred_aspect_terms.append(temp_12)\n",
    "        pred_aspect_sentiments.append(temp_22)\n",
    "\n",
    "# add new aspect term labels and aspect sentiment labels as columns to twemlab dataframe\n",
    "data_subset['aspect_term_preds'] = pred_aspect_terms\n",
    "data_subset['aspect_senti_preds'] = pred_aspect_sentiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59ca509",
   "metadata": {},
   "source": [
    "A sample of the added columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c995665",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_92ccb th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_92ccb_row0_col0, #T_92ccb_row0_col1, #T_92ccb_row0_col2, #T_92ccb_row1_col0, #T_92ccb_row1_col1, #T_92ccb_row1_col2, #T_92ccb_row2_col0, #T_92ccb_row2_col1, #T_92ccb_row2_col2, #T_92ccb_row3_col0, #T_92ccb_row3_col1, #T_92ccb_row3_col2, #T_92ccb_row4_col0, #T_92ccb_row4_col1, #T_92ccb_row4_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_92ccb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_92ccb_level0_col0\" class=\"col_heading level0 col0\" >Text</th>\n",
       "      <th id=\"T_92ccb_level0_col1\" class=\"col_heading level0 col1\" >Aspect Terms</th>\n",
       "      <th id=\"T_92ccb_level0_col2\" class=\"col_heading level0 col2\" >Aspect Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_92ccb_level0_row0\" class=\"row_heading level0 row0\" >7640</th>\n",
       "      <td id=\"T_92ccb_row0_col0\" class=\"data row0 col0\" >Please support my GoFundMe campaign: https://t.co/D2UUtzdcHF #GoFundMe https://t.co/sP7e9hTUBd</td>\n",
       "      <td id=\"T_92ccb_row0_col1\" class=\"data row0 col1\" >['GoFundMe']</td>\n",
       "      <td id=\"T_92ccb_row0_col2\" class=\"data row0 col2\" >['NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92ccb_level0_row1\" class=\"row_heading level0 row1\" >4706</th>\n",
       "      <td id=\"T_92ccb_row1_col0\" class=\"data row1 col0\" >@bancroft_lotty @SAMARASGIANNIS1 @iges2u @Jenny_S3005 @ASaramantinou @Heike622 @Annie2727 @inaxx68 @BuddyCoco64 @DeniseJoy71 @shannon_hausen @merryannie @KateBeckett8700 @KBRCAlways @captain_beckett @BitzIngeborg @Dalgaard2Mette @nadinesyd @pasburysmith @MDegen55 I wish you a Good night Lotty, sleep well and have a beautiful weekend and happy Saturday. 💚💙 https://t.co/D6IBgz32na</td>\n",
       "      <td id=\"T_92ccb_row1_col1\" class=\"data row1 col1\" >['Lotty,']</td>\n",
       "      <td id=\"T_92ccb_row1_col2\" class=\"data row1 col2\" >['NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'POSITIVE', 'POSITIVE', 'NEUTRAL', 'POSITIVE', 'POSITIVE', 'NEUTRAL', 'POSITIVE', 'POSITIVE', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'POSITIVE', 'NEUTRAL', 'NEUTRAL']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92ccb_level0_row2\" class=\"row_heading level0 row2\" >9759</th>\n",
       "      <td id=\"T_92ccb_row2_col0\" class=\"data row2 col0\" >Is Fagmeat a complete dickhead</td>\n",
       "      <td id=\"T_92ccb_row2_col1\" class=\"data row2 col1\" >['Fagmeat']</td>\n",
       "      <td id=\"T_92ccb_row2_col2\" class=\"data row2 col2\" >['NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE', 'NEGATIVE']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92ccb_level0_row3\" class=\"row_heading level0 row3\" >8240</th>\n",
       "      <td id=\"T_92ccb_row3_col0\" class=\"data row3 col0\" >@PaulCXBI No, all fixed up and ready to roll by 7!</td>\n",
       "      <td id=\"T_92ccb_row3_col1\" class=\"data row3 col1\" >['@PaulCXBI']</td>\n",
       "      <td id=\"T_92ccb_row3_col2\" class=\"data row3 col2\" >['NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92ccb_level0_row4\" class=\"row_heading level0 row4\" >9938</th>\n",
       "      <td id=\"T_92ccb_row4_col0\" class=\"data row4 col0\" >@billgates Joe briden https://t.co/IIwZt8PmvM</td>\n",
       "      <td id=\"T_92ccb_row4_col1\" class=\"data row4 col1\" >['@billgates', 'Joe briden']</td>\n",
       "      <td id=\"T_92ccb_row4_col2\" class=\"data row4 col2\" >['NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e6bf75c310>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract aspect term words and store in the dataframe\n",
    "aspect_terms = []\n",
    "\n",
    "# for every row (tweet)\n",
    "for idx, row in data_subset.iterrows():\n",
    "    row_aspect_terms = []\n",
    "    words = row['text'].split()\n",
    "    count_words = len(words)\n",
    "    count_terms = len(row['aspect_term_preds'])\n",
    "    \n",
    "    # check if words in text equals labels in aspect term prediction column\n",
    "    if count_words == count_terms:\n",
    "        \n",
    "        # for every word in tweet\n",
    "        for i in range(count_words):\n",
    "            if row['aspect_term_preds'][i] == 'B-AP':\n",
    "                term = words[i]\n",
    "\n",
    "                # if aspect term present, check further connected aspect terms\n",
    "                still_going = True\n",
    "                for j in range(i+1, count_words):\n",
    "                    if still_going == True:\n",
    "                        if row['aspect_term_preds'][j] == 'I-AP':\n",
    "                            term = term + ' ' + words[j]\n",
    "                        else:\n",
    "                            still_going = False\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                row_aspect_terms.append(term)\n",
    "\n",
    "        aspect_terms.append(row_aspect_terms)\n",
    "    \n",
    "    # if the count of words and aspect term labels don't match add a dash to list\n",
    "    # in the future maybe deal with this better --> look into it more\n",
    "    else:\n",
    "        aspect_terms.append('-')\n",
    "\n",
    "\n",
    "data_subset['aspect_terms'] = aspect_terms\n",
    "\n",
    "demo_cols = data_subset[['text','aspect_terms', 'aspect_senti_preds']]\n",
    "col_names = {'text': 'Text', 'aspect_terms': 'Aspect Terms', 'aspect_senti_preds': 'Aspect Sentiments'}\n",
    "demo_cols = demo_cols.rename(columns=col_names)\n",
    "demo_cols.sample(5).style.set_properties(**{'text-align': 'left'}).set_table_styles([dict(selector = 'th', props=[('text-align', 'left')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38324baa-d809-4fc7-8afe-97b8abd1a0c8",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m# for remaining words\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i, count_words):\n\u001b[1;32m---> 26\u001b[0m     \u001b[39mif\u001b[39;00m row[\u001b[39m'\u001b[39;49m\u001b[39maspect_term_preds\u001b[39;49m\u001b[39m'\u001b[39;49m][j] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mI-AP\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     27\u001b[0m         term \u001b[39m=\u001b[39m term \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m words[j]\n\u001b[0;32m     29\u001b[0m row_aspect_terms\u001b[39m.\u001b[39mappend(term)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# extract aspect term and sentiment and store in twemlab dataframe\n",
    "aspect_terms = []\n",
    "aspect_sentiments = []\n",
    "\n",
    "# for every row (tweet)\n",
    "for idx, row in data_subset.iterrows():\n",
    "    \n",
    "    row_aspect_terms = []\n",
    "    row_aspect_sentiments = [] \n",
    "\n",
    "    # get text length\n",
    "    words = row['text'].split()\n",
    "    count_words = len(words)\n",
    "    \n",
    "    # get token length (may differ from text length)\n",
    "    tokens = row['aspect_senti_preds']\n",
    "    token_counts = len(tokens)\n",
    "    \n",
    "    # for every word in tweet --> check if it's an aspect term and save\n",
    "    for i in range(count_words):\n",
    "        if row['aspect_term_preds'][i] == 'B-AP':\n",
    "            term = words[i]\n",
    "                   \n",
    "            # for remaining words\n",
    "            for j in range(i, count_words):\n",
    "                if row['aspect_term_preds'][j] == 'I-AP':\n",
    "                    term = term + ' ' + words[j]\n",
    "            \n",
    "            row_aspect_terms.append(term)\n",
    "    \n",
    "    aspect_terms.append(row_aspect_terms)\n",
    "    \n",
    "    # for every token --> extract sentiment\n",
    "    for i in range(token_counts):\n",
    "        if row['aspect_term_preds'][i] == 'B-AP':\n",
    "            sent = tokens[i]\n",
    "            \n",
    "            # for remaining tokens\n",
    "            for j in range(i, token_counts):\n",
    "                if row['aspect_term_preds'][j] == 'I-AP':\n",
    "                    sent = sent + ' ' + tokens[j]\n",
    "            \n",
    "            row_aspect_sentiments.append(sent)\n",
    "    \n",
    "    aspect_sentiments.append(row_aspect_sentiments)\n",
    "            \n",
    "data_subset['aspect_terms'] = aspect_terms\n",
    "data_subset['aspect_sentiments'] = aspect_sentiments\n",
    "\n",
    "demo_cols = data_subset[['text','label', 'sentiment_label','aspect_terms', 'aspect_sentiments']]\n",
    "col_names = {'text': 'Text', 'label': 'Label', 'sentimemt_label': 'Sentiment', 'aspect_terms': 'Aspect Terms', 'aspect_sentiments': 'Aspect Sentiments'}\n",
    "demo_cols = demo_cols.rename(columns=col_names)\n",
    "demo_cols.sample(5).style.set_properties(**{'text-align': 'left'}).set_table_styles([dict(selector = 'th', props=[('text-align', 'left')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "024ac158-96a2-407f-9a95-906141a4ab2c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 74587 isn't in this data subset\n"
     ]
    }
   ],
   "source": [
    "# example of non-matching text and aspect term labels\n",
    "indices = [index for index, _val in enumerate(data_subset)]\n",
    "\n",
    "if 74587 in indices:\n",
    "    text = data_subset.loc[74587,'text']\n",
    "    print(text)\n",
    "    print(len(text.split()))\n",
    "\n",
    "    terms = data_subset.loc[74587,'aspect_term_preds']\n",
    "    print(terms)\n",
    "    print(len(terms))\n",
    "    \n",
    "else:\n",
    "    print(\"index 74587 isn't in this data subset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRACE_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d330c58e3bb01c9a6aa22fdc5b13d0bc6cc6d676164106ca161027b468300435"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
